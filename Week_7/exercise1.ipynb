{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from nltk.text import Text\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if os.getcwd()[-1] in '0123456789':\n",
    "    path_parent = os.path.dirname(os.getcwd())\n",
    "    os.chdir(path_parent)\n",
    "\n",
    "paper_abstracts = pd.read_csv(\"BigData/paper_abstract_dataset.csv\")\n",
    "paper_abstracts = paper_abstracts[paper_abstracts['Abstract'].notna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "from string import punctuation\n",
    "punctuation = list(punctuation)\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "import re\n",
    "\n",
    "tokens = []\n",
    "\n",
    "def get_tokens(abstract):\n",
    "    abstract = abstract.lower()\n",
    "    tokens_raw = word_tokenize(abstract)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in tokens_raw:\n",
    "        if bool(re.search(r'\\d+', token)):\n",
    "            continue\n",
    "        elif token in punctuation or token in stopwords:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        ps.stem(token)\n",
    "        tokens.append(token)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_abstracts.insert(2, \"Tokens\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[39mif\u001B[39;00m i \u001B[39m%\u001B[39m \u001B[39m1000\u001B[39m \u001B[39m==\u001B[39m \u001B[39m0\u001B[39m:\n\u001B[0;32m      3\u001B[0m     \u001B[39mprint\u001B[39m(i)\n\u001B[1;32m----> 4\u001B[0m paper_abstracts[\u001B[39m\"\u001B[39m\u001B[39mTokens\u001B[39m\u001B[39m\"\u001B[39m][i] \u001B[39m=\u001B[39m get_tokens(row)\n",
      "Cell \u001B[1;32mIn[6], line 25\u001B[0m, in \u001B[0;36mget_tokens\u001B[1;34m(abstract)\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[39melif\u001B[39;00m token \u001B[39min\u001B[39;00m punctuation \u001B[39mor\u001B[39;00m token \u001B[39min\u001B[39;00m stopwords:\n\u001B[0;32m     23\u001B[0m         \u001B[39mcontinue\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m     ps\u001B[39m.\u001B[39;49mstem(token)\n\u001B[0;32m     26\u001B[0m     tokens\u001B[39m.\u001B[39mappend(token)\n\u001B[0;32m     28\u001B[0m \u001B[39mreturn\u001B[39;00m tokens\n",
      "File \u001B[1;32mc:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\stem\\porter.py:672\u001B[0m, in \u001B[0;36mPorterStemmer.stem\u001B[1;34m(self, word, to_lowercase)\u001B[0m\n\u001B[0;32m    670\u001B[0m stem \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_step1b(stem)\n\u001B[0;32m    671\u001B[0m stem \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_step1c(stem)\n\u001B[1;32m--> 672\u001B[0m stem \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_step2(stem)\n\u001B[0;32m    673\u001B[0m stem \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_step3(stem)\n\u001B[0;32m    674\u001B[0m stem \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_step4(stem)\n",
      "File \u001B[1;32mc:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\stem\\porter.py:513\u001B[0m, in \u001B[0;36mPorterStemmer._step2\u001B[1;34m(self, word)\u001B[0m\n\u001B[0;32m    510\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mmode \u001B[39m==\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mMARTIN_EXTENSIONS:\n\u001B[0;32m    511\u001B[0m     rules\u001B[39m.\u001B[39mappend((\u001B[39m\"\u001B[39m\u001B[39mlogi\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39m\"\u001B[39m\u001B[39mlog\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_has_positive_measure))\n\u001B[1;32m--> 513\u001B[0m \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_apply_rule_list(word, rules)\n",
      "File \u001B[1;32mc:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\stem\\porter.py:266\u001B[0m, in \u001B[0;36mPorterStemmer._apply_rule_list\u001B[1;34m(self, word, rules)\u001B[0m\n\u001B[0;32m    263\u001B[0m     \u001B[39melse\u001B[39;00m:\n\u001B[0;32m    264\u001B[0m         \u001B[39m# Don't try any further rules\u001B[39;00m\n\u001B[0;32m    265\u001B[0m         \u001B[39mreturn\u001B[39;00m word\n\u001B[1;32m--> 266\u001B[0m \u001B[39mif\u001B[39;00m word\u001B[39m.\u001B[39mendswith(suffix):\n\u001B[0;32m    267\u001B[0m     stem \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_replace_suffix(word, suffix, \u001B[39m\"\u001B[39m\u001B[39m\"\u001B[39m)\n\u001B[0;32m    268\u001B[0m     \u001B[39mif\u001B[39;00m condition \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m \u001B[39mor\u001B[39;00m condition(stem):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(paper_abstracts['Abstract']):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    paper_abstracts[\"Tokens\"][i] = get_tokens(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "376dd7633afddb7e11c0a9ffa5f656d1a19ddfafae55033d07193535982b765e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
